{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83066cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 軽量CNNモデルの読み込み\n",
    "model = tf.keras.models.load_model('model/speech_commands_cnn.h5')\n",
    "\n",
    "COMMANDS = ['left', 'right', 'forward', 'stop', 'go']\n",
    "NEXTJS_LOG_URL = \"https://your-nextjs-app.vercel.app/api/log\"\n",
    "\n",
    "@app.route('/recognize', methods=['POST'])\n",
    "def recognize_audio():\n",
    "    audio_data = request.files['audio']\n",
    "\n",
    "    # 前処理\n",
    "    processed_audio = preprocess_audio(audio_data)\n",
    "\n",
    "    # CNN推論\n",
    "    prediction = model.predict(processed_audio)\n",
    "    command = COMMANDS[np.rgmax(prediction)]\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    # Next.jsにログ送信\n",
    "    log_data = {\n",
    "        'command': command,\n",
    "        'confidence': confidence,\n",
    "        'timestamp': time.time()\n",
    "    }\n",
    "    requestspost(NEXTJS_LOG_URL, json=log_data)\n",
    "\n",
    "    return jsonify({\n",
    "        'command': command,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "\n",
    "def preprocess_audio(audio_file):\n",
    "    # MFCC特徴量抽出など\n",
    "    pass\n",
    "\n",
    "# Colabで実行\n",
    "app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speech_commands_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(len(COMMANDS), activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
